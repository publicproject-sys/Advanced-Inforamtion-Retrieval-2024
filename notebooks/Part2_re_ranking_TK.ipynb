{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e093d38d-02e5-4dcd-b4d4-fe37ec736bba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2 - Neural Re-Ranking **40 points**\n",
    "\n",
    "Implement 2 neural architectures based on the kernel-pooling paradigm to perform re-ranking in ``src/re_ranking.py`` (KNRM, TK)\n",
    "\n",
    "- Implement: the 2 (KNRM, TK) model classes **20 points**\n",
    "   - Show that you understood what happens by adding comments to difficult parts of the model (what tensor dimensions represent, what gets summed up, etc..)\n",
    "- Implement: training process & result evaluation **10 points**\n",
    "    - Including early stopping based on the validation set\n",
    "\t   - Use the **msmarco_tuples.validation.tsv** input to feed the neural models and **msmarco_qrels.txt** qrels to evaluate the output\n",
    "- Evaluate: Compute a test set evaluation at the end  **10 points**\n",
    "\t- MS-MARCO sparse labels\n",
    "\t  - Use the **msmarco_tuples.test.tsv** input to feed the neural models and **msmarco_qrels.txt** qrels to evaluate the output\n",
    "\t- FiRA-2022 fine-grained labels on out-of-domain data\n",
    "\t  - Use your created created labels from part 1\n",
    "\t     - Use the **fira-2022.tuples.tsv** input to feed the neural models and your qrels from part 1 to evaluate the output\n",
    "\t  - Compare these results with our baseline label creation method\n",
    "\t     - Use the **fira-2022.tuples.tsv** input to feed the neural models and **fira-2022.baseline-qrels.tsv** qrels to evaluate the output\n",
    "\t  - Explore & describe the differences in metrics between the baseline and your label creation \n",
    "\n",
    "## Provided data:\n",
    "* AllenNLP vocabulary (collection specific, in two sizes: use the _10 = min of 10 occurrences in the collection if you have memory problems with the _5)\n",
    "* train triples\n",
    "* evaluation tuples (validation & test) with 2.000 queries each and the top 40 BM25 results per query, relevance judgments (qrels, one file covering both validation & test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3354dd-b54e-40ee-bc18-ea4541ea4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put in your basepath like for example \"/home/studio-lab-user/src/data_part2\"\n",
    "base_path = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c092daf-8975-45fb-8d4b-14fe77842c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Iterator, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_loading import IrTripleDatasetReader, IrLabeledTupleDatasetReader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "\n",
    "from src.data_loading import *\n",
    "# from src.model_knrm import *\n",
    "from src.model_tk import *\n",
    "from allennlp.data.dataloader import PyTorchDataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "\n",
    "from typing import Dict, Iterator, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import GELU\n",
    "\n",
    "\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
    "\n",
    "import os\n",
    "\n",
    "from src.model_tk import TK\n",
    "\n",
    "from src.BatchWordEmbedder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77569846-ec65-4daa-8f92-66f786e38e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import your local base path\n",
    "\n",
    "import os\n",
    "\n",
    "config = {\n",
    "    \"vocab_directory\": os.path.join(base_path, \"data/Part-2/allen_vocab_lower_10\"),\n",
    "    \"pre_trained_embedding\": os.path.join(base_path, \"data/Part-2/glove.42B.300d.txt\"),\n",
    "    \"model\": \"tk\",\n",
    "    \"train_data\": os.path.join(base_path, \"data/Part-2/triples.train.tsv\"),\n",
    "    \"validation_data\": os.path.join(base_path, \"data/Part-2/msmarco_tuples.validation.tsv\"),\n",
    "    \"test_data\": os.path.join(base_path, \"data/Part-2/tuples.test.tsv\"),\n",
    "    \"qrels\": os.path.join(base_path, \"data/Part-2/msmarco_qrels.txt\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ea8c97-7823-4def-abd1-39ac4f3df415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a6a22223a342b395fbe85aecffc7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "vocab = Vocabulary.from_files(config[\"vocab_directory\"])\n",
    "tokens_embedder = Embedding(vocab=vocab,\n",
    "                           pretrained_file= config[\"pre_trained_embedding\"],\n",
    "                           embedding_dim=300,\n",
    "                           trainable=True,\n",
    "                           padding_index=0,\n",
    "                           )\n",
    "word_embedder = BasicTextFieldEmbedder({\"tokens\": tokens_embedder})\n",
    "\n",
    "_triple_reader = IrTripleDatasetReader(lazy=True, max_doc_length=128, max_query_length=128)\n",
    "_triple_reader = _triple_reader.read(config[\"train_data\"])\n",
    "_triple_reader.index_with(vocab)\n",
    "loader = PyTorchDataLoader(_triple_reader, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c716a0-94b5-4b7f-b322-e4483052ade9",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2877b15-771f-4975-80f5-c0f277134ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "batch_embedder = BatchWordEmbedder(word_embedder, device)\n",
    "\n",
    "tk_config = {\n",
    "            \"n_kernels\": 11,\n",
    "            \"max_len\": 128,\n",
    "            \"n_heads\": 4,\n",
    "            \"num_layers\": 2,\n",
    "            \"hidden_dim\": 128,\n",
    "            \"word_embedding_dim\": 300,\n",
    "            \"dropout\": 0.1,\n",
    "            \"debug\" : False,\n",
    "            \"batch_size\" : BATCH_SIZE,\n",
    "        }\n",
    "\n",
    "model_tk = TK(**tk_config).to(device)\n",
    "\n",
    "max_iter = 500000\n",
    "step_size = max_iter//BATCH_SIZE//2\n",
    "\n",
    "training_parameters = {\n",
    "    \"optimizer_lr\" : 1 * 1e-3,\n",
    "    \"optimizer_weight_decay\": 1e-5, # don't use with scheduler\n",
    "    \"scheduler_step_size\": step_size,\n",
    "    \"scheduler_gamma\": 0.5, # for 10 reductions of lr it will reduce it to 0.1073741824 of the original value\n",
    "    \"training_max_iter\": max_iter # or None to train on the entire training set\n",
    "} \n",
    "\n",
    "# optimizer = torch.optim.Adam(model_tk.parameters(), lr=training_parameters[\"optimizer_lr\"], weight_decay=training_parameters[\"optimizer_weight_decay\"])\n",
    "optimizer = torch.optim.Adam(model_tk.parameters(), lr = training_parameters[\"optimizer_lr\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    gamma = training_parameters[\"scheduler_gamma\"],\n",
    "    step_size = training_parameters[\"scheduler_step_size\"]\n",
    ")\n",
    "\n",
    "loss_criterion = torch.nn.MarginRankingLoss(margin=1, reduction='elementwise_mean').to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326d6b93-a5d5-4c55-941a-8b2812b9140e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09122df8711b4205a906cc2e8c8218e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgrebnev/anaconda3/envs/air_ex2/lib/python3.6/site-packages/torch/nn/_reduction.py:14: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batches: 0, Total triples: 0/500000, Average Loss: None, Current loss: [0.001]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8fcf67572ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_tk_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_accumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_tk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_embedder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training_max_iter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/rgrebnev/Documents/ss_2024/air/ex2/air-2024-group_32/src/BatchWordEmbedder.py\u001b[0m in \u001b[0;36mtk_training_loop\u001b[0;34m(model, loader, optimizer, scheduler, loss_criterion, batch_embedder, device, max_iter, epochs, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mquery_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_pos_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_neg_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_pad_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_pad_mask_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_pad_mask_neg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgrebnev/anaconda3/envs/air_ex2/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rgrebnev/anaconda3/envs/air_ex2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_tk_trained, loss_accumulator = tk_training_loop(model_tk, loader, optimizer, scheduler, loss_criterion, batch_embedder, device, training_parameters['training_max_iter'], epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94d05d56-fc31-4793-a005-fb11191b18ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model_tk_trained.state_dict(), \"../models/model_tk_trained_500k.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c50c24-effb-4cae-9b8c-803eb46987af",
   "metadata": {},
   "source": [
    "**Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed10332-271b-4eff-8f4e-c44b79ed5ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the path to the pre-trained model\n",
    "model_path = os.path.join(base_path, \"models/model_tk_trained_500k.pt\")\n",
    "\n",
    "# Define the configuration for TK model initialization\n",
    "tk_config = {\n",
    "    \"n_kernels\": 11,\n",
    "    \"max_len\": 128,\n",
    "    \"n_heads\": 4,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"word_embedding_dim\": 300,\n",
    "    \"dropout\": 0.1,\n",
    "    \"debug\": False,\n",
    "    \"batch_size\": BATCH_SIZE,  # Define BATCH_SIZE if it's not already defined\n",
    "}\n",
    "\n",
    "# Initialize the TK model\n",
    "model_tk = TK(**tk_config).to(device)\n",
    "\n",
    "# Load the model state_dict\n",
    "model_tk.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf4fcc-6a67-45d1-9b02-50b419664bb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "**MS Marco Sparse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83db8c8f-00e4-4e13-96b6-ef7ad3173351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read txt file\n",
    "df_qrels = pd.DataFrame()\n",
    "list_qrels = []\n",
    "with open(config['qrels']) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        query_id, _, doc_id, _ = line.split()\n",
    "        list_qrels.append([query_id, doc_id])\n",
    "df_qrels = pd.DataFrame(list_qrels, columns=['query_id', 'doc_id'])\n",
    "df_qrels['query_id'] = df_qrels['query_id'].astype(int)\n",
    "df_qrels['doc_id'] = df_qrels['doc_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8813b2c5-395d-480e-bea5-d17538f55974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "batch_embedder_eval = BatchWordEmbedder(word_embedder, device, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47bd146c-badf-4555-9286-9674ade180fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_triple_reader_eval = IrLabeledTupleDatasetReader(lazy=True, max_doc_length=128, max_query_length=128)\n",
    "_triple_reader_eval = _triple_reader_eval.read(config[\"validation_data\"])\n",
    "_triple_reader_eval.index_with(vocab)\n",
    "loader_test = PyTorchDataLoader(_triple_reader_eval, batch_size=64)\n",
    "# batch = next(iter(loader_test))\n",
    "# batch_embedder_eval = BatchWordEmbedder(word_embedder, device, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7fbfe05-0bd0-405b-b35d-44498c0023e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, df_qrels, loader, batch_embedder, device):\n",
    "    model.eval()\n",
    "    query_ids = []\n",
    "    doc_ids = []\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(loader):\n",
    "            query_emb, doc_pos_emb, _, query_pad_mask, document_pad_mask_pos, _ = batch_embedder(batch)\n",
    "            pred = model(query_emb, doc_pos_emb, query_pad_mask, document_pad_mask_pos)\n",
    "            query_ids.extend(batch['query_id'])  # Directly extend the list\n",
    "            doc_ids.extend(batch['doc_id'])      # Directly extend the list\n",
    "            preds.extend(pred.cpu().numpy().flatten())\n",
    "            # if idx * 32 >= 10000:\n",
    "            #     break\n",
    "    df_eval = pd.DataFrame({\n",
    "        'query_id': query_ids,\n",
    "        'doc_id': doc_ids,\n",
    "        'score': preds\n",
    "    })\n",
    "    \n",
    "    # Assigning rank based on scores within each query_id group\n",
    "    df_eval['rank'] = df_eval.groupby('query_id')['score'].rank(ascending=False, method='first').astype(int)\n",
    "    \n",
    "    # Sorting by query_id and rank\n",
    "    df_eval = df_eval.sort_values(by=['query_id', 'rank'])\n",
    "    \n",
    "    return df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a83bfd03-2dc2-4556-9edb-c6394dfe2651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b99e290d7434e17bbf2069dd4137589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eval = evaluate_model(model_tk, df_qrels, loader_test, batch_embedder_eval, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7106a56-a4ce-4a84-8eaa-4e4725fca3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the specific paths relative to the base path\n",
    "path_result = os.path.join(base_path, \"data/results_part2/tk_msmarco_ranking_final.tsv\")\n",
    "path_baseline = config['qrels']\n",
    "\n",
    "# Write the DataFrame to a TSV file\n",
    "df_eval.to_csv(path_result, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de37f775-9316-4e9b-81d5-9e675273f691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRR@10': 0.2317813492063492,\n",
       " 'Recall@10': 0.4657083333333334,\n",
       " 'QueriesWithNoRelevant@10': 1050,\n",
       " 'QueriesWithRelevant@10': 950,\n",
       " 'AverageRankGoldLabel@10': 3.5652631578947367,\n",
       " 'MedianRankGoldLabel@10': 3.0,\n",
       " 'MRR@20': 0.236783314466751,\n",
       " 'Recall@20': 0.5342916666666666,\n",
       " 'QueriesWithNoRelevant@20': 910,\n",
       " 'QueriesWithRelevant@20': 1090,\n",
       " 'AverageRankGoldLabel@20': 4.963302752293578,\n",
       " 'MedianRankGoldLabel@20': 3.0,\n",
       " 'MRR@1000': 0.23825244675891408,\n",
       " 'Recall@1000': 0.574625,\n",
       " 'QueriesWithNoRelevant@1000': 830,\n",
       " 'QueriesWithRelevant@1000': 1170,\n",
       " 'AverageRankGoldLabel@1000': 6.558119658119658,\n",
       " 'MedianRankGoldLabel@1000': 4.0,\n",
       " 'nDCG@3': 0.21571062590580198,\n",
       " 'nDCG@5': 0.251545146323757,\n",
       " 'nDCG@10': 0.2858396956732744,\n",
       " 'nDCG@20': 0.3036647891248599,\n",
       " 'nDCG@1000': 0.3121836066107091,\n",
       " 'QueriesRanked': 2000,\n",
       " 'MAP@1000': 0.23467543810810212}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.core_metrics import calculate_metrics_plain,load_ranking,load_qrels\n",
    "\n",
    "calculate_metrics_plain(load_ranking(path_result),load_qrels(path_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555fd11d-9f00-407f-936b-58749d5bb396",
   "metadata": {
    "tags": []
   },
   "source": [
    "**fira-2022.tuples.tsv input to feed the neural models and fira-2022.baseline-qrels.tsv for evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a822356f-d947-4f19-bbb0-cd6808c6debe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_directory\": os.path.join(base_path, \"data/Part-2/allen_vocab_lower_10\"),\n",
    "    \"pre_trained_embedding\": os.path.join(base_path, \"data/Part-2/glove.42B.300d.txt\"),\n",
    "    \"model\": \"tk\",\n",
    "    \"train_data\": os.path.join(base_path, \"data/Part-2/triples.train.tsv\"),\n",
    "    \"validation_data\": os.path.join(base_path, \"data/Part-2/fira-22.tuples_mod.tsv\"),\n",
    "    \"test_data\": os.path.join(base_path, \"data/Part-2/tuples.test.tsv\"),\n",
    "    \"qrels\": os.path.join(base_path, \"data/Part-2/fira-22.baseline-qrels.tsv\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7a8fd95-777e-4805-80b2-fa282311b5d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Specify the path to your file\n",
    "\n",
    "# Initialize an empty list to store [query_id, doc_id] pairs\n",
    "list_qrels = []\n",
    "\n",
    "# Read the file line by line and process each line\n",
    "with open(config['qrels']) as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()  # Split line by tab separator\n",
    "        if len(parts) >= 4:  # Check if we have at least 4 parts\n",
    "            query_id = parts[0]  # First column\n",
    "            doc_id = parts[2]    # Third column\n",
    "            list_qrels.append([query_id, doc_id])  # Append [query_id, doc_id] to list_qrels\n",
    "        else:\n",
    "            print(f\"Warning: Skipping line with unexpected format: {line}\")\n",
    "            print(f\"The were so many part: {len(parts)}\")\n",
    "\n",
    "# Create a DataFrame from list_qrels with columns 'query_id' and 'doc_id'\n",
    "df_qrels = pd.DataFrame(list_qrels, columns=['query_id', 'doc_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dc15f56-a293-4d91-8600-49db3341fa49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "batch_embedder_eval = BatchWordEmbedder(word_embedder, device, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6499f459-5e87-4205-92f8-8cf65d370709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_tuple_reader_eval = IrLabeledTupleDatasetReader(lazy=True, max_doc_length=512, max_query_length=512)\n",
    "_tuple_reader_eval = _tuple_reader_eval.read(config['validation_data'])\n",
    "_tuple_reader_eval.index_with(vocab)\n",
    "loader_test = PyTorchDataLoader(_tuple_reader_eval, batch_size=64)\n",
    "# batch = next(iter(loader_test))\n",
    "# batch_embedder_eval = BatchWordEmbedder(word_embedder, device, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db241f2c-d043-4384-a4f0-90e0202ada9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, df_qrels, loader, batch_embedder, device):\n",
    "    model.eval()\n",
    "    query_ids = []\n",
    "    doc_ids = []\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(loader):\n",
    "            try:\n",
    "                query_emb, doc_pos_emb, _, query_pad_mask, document_pad_mask_pos, _ = batch_embedder(batch)\n",
    "                pred = model(query_emb, doc_pos_emb, query_pad_mask, document_pad_mask_pos)\n",
    "                query_ids.extend(batch['query_id'])  # Directly extend the list\n",
    "                doc_ids.extend(batch['doc_id'])      # Directly extend the list\n",
    "                preds.extend(pred.cpu().numpy().flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch {idx}: {e}\")\n",
    "                print(\"Skipping batch with query_id and doc_id:\")\n",
    "                print(\"query_id:\", batch['query_id'])\n",
    "                print(\"doc_id:\", batch['doc_id'])\n",
    "                continue\n",
    "            # if idx * 32 >= 10000:\n",
    "            #     break\n",
    "    print(\"Finished!\")\n",
    "    df_eval = pd.DataFrame({\n",
    "        'query_id': query_ids,\n",
    "        'doc_id': doc_ids,\n",
    "        'score': preds\n",
    "    })\n",
    "    \n",
    "    # Assigning rank based on scores within each query_id group\n",
    "    df_eval['rank'] = df_eval.groupby('query_id')['score'].rank(ascending=False, method='first').astype(int)\n",
    "    \n",
    "    # Sorting by query_id and rank\n",
    "    df_eval = df_eval.sort_values(by=['query_id', 'rank'])\n",
    "    \n",
    "    return df_eval\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db35415f-58b3-4612-ba4f-24791c0e6504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84e15a548c541448443614d08c97363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading instances: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "df_eval = evaluate_model(model_tk, df_qrels, loader_test, batch_embedder_eval, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e06fd4-5708-40fd-8a10-592a71bd374c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Write the DataFrame to a TSV file\n",
    "path_result= os.path.join(base_path, \"data/results_part2/tk_fira_baseline_final.tsv\")\n",
    "path_baseline=config['qrels']\n",
    "#Write this to the results\n",
    "df_eval.to_csv(path_result, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08b9fc12-6c00-4642-8cda-45730a598b35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRR@10': 0.9584031198686371,\n",
       " 'Recall@10': 0.9514386291048853,\n",
       " 'QueriesWithNoRelevant@10': 115,\n",
       " 'QueriesWithRelevant@10': 4060,\n",
       " 'AverageRankGoldLabel@10': 1.0970443349753694,\n",
       " 'MedianRankGoldLabel@10': 1.0,\n",
       " 'MRR@20': 0.9584031198686371,\n",
       " 'Recall@20': 1.0000527797325827,\n",
       " 'QueriesWithNoRelevant@20': 115,\n",
       " 'QueriesWithRelevant@20': 4060,\n",
       " 'AverageRankGoldLabel@20': 1.0970443349753694,\n",
       " 'MedianRankGoldLabel@20': 1.0,\n",
       " 'MRR@1000': 0.9584031198686371,\n",
       " 'Recall@1000': 1.0000527797325827,\n",
       " 'QueriesWithNoRelevant@1000': 115,\n",
       " 'QueriesWithRelevant@1000': 4060,\n",
       " 'AverageRankGoldLabel@1000': 1.0970443349753694,\n",
       " 'MedianRankGoldLabel@1000': 1.0,\n",
       " 'nDCG@3': 0.8754531745450254,\n",
       " 'nDCG@5': 0.8804138103150848,\n",
       " 'nDCG@10': 0.9045552653589506,\n",
       " 'nDCG@20': 0.9177484694976151,\n",
       " 'nDCG@1000': 0.9177484694976151,\n",
       " 'QueriesRanked': 4060,\n",
       " 'MAP@1000': 0.9500647311370559}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from src.core_metrics import calculate_metrics_plain,load_ranking,load_qrels\n",
    "\n",
    "calculate_metrics_plain(load_ranking(path_result),load_qrels(path_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1b427-783e-4c55-a0ee-214e2c6859a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "**FIRA our own judgement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fed500c-2a5d-4c18-8fc7-a837f9958cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRR@10': 0.9506052026916134,\n",
       " 'Recall@10': 0.9521341793498367,\n",
       " 'QueriesWithNoRelevant@10': 113,\n",
       " 'QueriesWithRelevant@10': 4062,\n",
       " 'AverageRankGoldLabel@10': 1.1164451009354996,\n",
       " 'MedianRankGoldLabel@10': 1.0,\n",
       " 'MRR@20': 0.9506052026916134,\n",
       " 'Recall@20': 1.000052753745516,\n",
       " 'QueriesWithNoRelevant@20': 113,\n",
       " 'QueriesWithRelevant@20': 4062,\n",
       " 'AverageRankGoldLabel@20': 1.1164451009354996,\n",
       " 'MedianRankGoldLabel@20': 1.0,\n",
       " 'MRR@1000': 0.9506052026916134,\n",
       " 'Recall@1000': 1.000052753745516,\n",
       " 'QueriesWithNoRelevant@1000': 113,\n",
       " 'QueriesWithRelevant@1000': 4062,\n",
       " 'AverageRankGoldLabel@1000': 1.1164451009354996,\n",
       " 'MedianRankGoldLabel@1000': 1.0,\n",
       " 'nDCG@3': 0.8660275945797691,\n",
       " 'nDCG@5': 0.873464277441999,\n",
       " 'nDCG@10': 0.8987960356282988,\n",
       " 'nDCG@20': 0.9118463607058193,\n",
       " 'nDCG@1000': 0.9118463607058193,\n",
       " 'QueriesRanked': 4062,\n",
       " 'MAP@1000': 0.9398758982965247}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_baseline_own=os.path.join(base_path,\"data/Part-1/fira-22.judgements-anonymized-aggregated_v1.tsv\")\n",
    "calculate_metrics_plain(load_ranking(path_result),load_qrels(path_baseline_own))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee401f72-9d73-4f5e-8f83-96bcf7937dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air_ex2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
